# LSBATCH: User input
#!/bin/bash
# V100 GPUs with up to 32GB of memory each
# The queue that we want to submit our job to.
# In this case it is the V100 GPUs, but there's also equvalent
# queues for A100, such as gpua100.
#BSUB -q gpuv100
# The name of the job. Will e.g. be shown using the `bstat` command.
#BSUB -J p_c_s_n
# The number of cores that we want to allocate, this is equavalent
# to the total number of cores for the whole job, so if we wish to
# run 32 threads on 4 nodes, this number need to be 128.
#BSUB -n 4
# Specifics on the GPU allocation.
# In this case one GPU with exclusive access.
# The `num` can be changed up to the total number of GPUs on the node.
#BSUB -gpu "num=1:mode=exclusive_process"
# Total walltime of the program, How much time do we expect it to run.
# When this time has passed the program WILL be killed if it is not
# comlete.
#BSUB -W 04:00
# How much memory do we want to allocate per core allocated.
# In this case we will have 4x16GB as we have 4 cores
#BSUB -R "rusage[mem=16GB]"
# How do we want the cores distributed.
# `hosts=1` mean that we want all cores on the same node.
#BSUB -R "span[hosts=1]"

# stdout and stderr files
#BSUB -o "out/jobs/pic_cc_short_nodet_%J.out"
#BSUB -e "out/jobs/pic_cc_short_nodet_%J.err"

mkdir -p out/jobs

./out/pic_cc_short_nodet bench > out/jobs/pic_cc_short_nodet_${LSB_JOBID}.log